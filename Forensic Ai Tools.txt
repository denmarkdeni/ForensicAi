
pip install 
deepface 
dlib 
opencv-python 
numpy 
tensorflow 
keras 
pytesseract 
spacy 
nltk
---------------------------------------------------------------------------
Facial Recognition (DeepFace & Dlib)

from deepface import DeepFace

def analyze_face(image_path):
    result = DeepFace.analyze(image_path, actions=['age', 'gender', 'emotion'])
    return result

# Example Usage
face_result = analyze_face("suspect.jpg")
print(face_result)
----------------------------------------------------------------
Image Analysis (Object Detection using OpenCV + YOLO)

import cv2

def detect_objects(image_path):
    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    
    return edges

# Example Usage
edges = detect_objects("evidence.jpg")
cv2.imshow("Edges", edges)
cv2.waitKey(0)

----------------------------------------------------------------
Video Analysis (Face & Motion Detection using OpenCV)

import cv2

def process_video(video_path):
    cap = cv2.VideoCapture(video_path)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        cv2.imshow('Frame', gray)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()

# Example Usage
process_video("footage.mp4")
----------------------------------------------------------------

Text Analysis (OCR with Tesseract & NLP with spaCy)

import pytesseract
from PIL import Image

def extract_text(image_path):
    text = pytesseract.image_to_string(Image.open(image_path))
    return text

# Example Usage
document_text = extract_text("document.png")
print(document_text)
----------------------------------------------------------------
Text Processing (NER with spaCy)

import spacy

nlp = spacy.load("en_core_web_sm")

def analyze_text(text):
    doc = nlp(text)
    for ent in doc.ents:
        print(f"{ent.text} ({ent.label_})")

# EXAMPLE USAGE
analyze_text("John Doe was last seen at New York on 5th Feb 2025.")


import cv2
import pytesseract

# Path to Image
img_path = r"C:\Users\Admin\Desktop\Maria Deniston\ForensicAi\Forensic_App\static\images\test4.jpg"
# Load Image
image = cv2.imread(img_path)

# Convert to Grayscale
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Apply Thresholding to remove noise
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

# Run OCR
custom_config = r'--oem 3 --psm 6'  # Use appropriate OCR mode
text = pytesseract.image_to_string(thresh, config=custom_config)

print("Extracted Text:", text)

from transformers import pipeline

# Load AI Model for Grammar Correction
corrector = pipeline("text2text-generation", model="facebook/bart-large-cnn")

# Correct OCR text
corrected_text = corrector(text)[0]['generated_text']
print("Corrected Text:", corrected_text)
